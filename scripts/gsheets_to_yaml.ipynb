{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This notebook fetches BDM Trial specs from the Google Sheet and then generates documentations in quarto markdown format.\n",
    "\n",
    "The generated markdown files are saved in the `assets/yml/tables/` folder.\n",
    "\n",
    "Install pandas, gspread, and PyYAML before running this notebook:\n",
    "\n",
    "```bash\n",
    "pip install pandas gspread PyYAML\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "OUTPUT_DIR = Path('assets/auto-generated/')  # where to write the generated files\n",
    "TRIAL_SPEC_SHEET_ID = os.environ.get('TRIAL_SPEC_SHEET_ID', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def camel_to_dash(camel_case_string):\n",
    "  \"\"\"Converts a CamelCase string to a dash-separated lower case string.\n",
    "\n",
    "  Args:\n",
    "    camel_case_string: The CamelCase string to convert.\n",
    "\n",
    "  Returns:\n",
    "    The dash-separated lower-case string.\n",
    "  \"\"\"\n",
    "  import re\n",
    "\n",
    "  if pd.isna(camel_case_string):\n",
    "    raise ValueError('camel_case_string cannot be None')\n",
    "\n",
    "  if camel_case_string.strip() == '':\n",
    "    return camel_case_string.strip()\n",
    "\n",
    "  # replace spaces with empty string, and prefix uppercase letters with a dash\n",
    "  s = re.sub('(?!^)([A-Z]+)', r'-\\1', camel_case_string.replace(' ', ''))\n",
    "  return s.lower()\n",
    "\n",
    "def get_sheet(sheet_id: str, sheet_name, backend: str='requests'):\n",
    "    \"\"\"Download a Google Sheets table as a pandas DataFrame.\"\"\"\n",
    "    url = ('https://docs.google.com/spreadsheets/d/'\n",
    "           '{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}')\n",
    "    url = url.format(sheet_id=sheet_id, sheet_name=sheet_name)\n",
    "    if backend.lower() == 'requests':\n",
    "      import requests\n",
    "      from io import StringIO\n",
    "      content = requests.get(url).content\n",
    "      data = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "    else:\n",
    "      data = pd.read_csv(url)\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_sheet_to_yaml(table_info: pd.Series, root_dir) -> Path:\n",
    "    \"\"\"Write a pandas DataFrame to a CSV file.\"\"\"\n",
    "\n",
    "    assert table_info['name'] is not None, 'table name is required'\n",
    "\n",
    "    file_name = camel_to_dash(table_info['name']) + '.yml'\n",
    "    output_path = root_dir / file_name\n",
    "\n",
    "    # append the category to the file name if it exists\n",
    "    if (pd.notna(table_info['category']) and len(table_info['category']) > 0):\n",
    "      category = camel_to_dash(table_info['category'])\n",
    "      output_path = root_dir / category / file_name\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = get_sheet(TRIAL_SPEC_SHEET_ID, table_info['name'])\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "\n",
    "      # FIXME - this is a hack to handle the fact that the glossary description is in the same sheet as the glossary\n",
    "      glossary_categories_df = None\n",
    "      if 'glossary' in df['data_type'].unique():\n",
    "        glossary_categories_df = df[df['data_type'] == 'glossary']\n",
    "        df = df.drop(glossary_categories_df.index)\n",
    "\n",
    "      data = df.groupby('category', sort=False).apply(\n",
    "        lambda x: x.to_dict(orient='records'), include_groups=False).to_dict()\n",
    "\n",
    "      # reformat data to be a list of dictionaries\n",
    "      data = [{'category': c, 'fields': v} for  c,v in data.items()]\n",
    "\n",
    "      # FIXME - this is a hack to handle the fact that the glossary description is in the same sheet as the glossary - see above too\n",
    "      if glossary_categories_df is not None:\n",
    "        for d in data:\n",
    "          catg = d['category']\n",
    "          if catg in glossary_categories_df['name'].values:\n",
    "            catg_info = glossary_categories_df.query('name == @catg').iloc[0].to_dict()\n",
    "            # TODO append all columns\n",
    "            d['description'] = catg_info['description'] if pd.notna(catg_info['description']) else ''\n",
    "            d['publish'] = catg_info['publish'] if pd.notna(catg_info['publish']) else False\n",
    "\n",
    "      yaml.dump(\n",
    "        data,\n",
    "        f, default_flow_style=False, indent=2, sort_keys=False)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "\n",
    "tables = get_sheet(TRIAL_SPEC_SHEET_ID, 'Tables')\n",
    "tables = tables.query('publish == True')\n",
    "tables['category'] = tables['category'].str.split('; ')\n",
    "tables = tables.explode('category').reset_index(drop=True)\n",
    "\n",
    "tables.apply(convert_sheet_to_yaml, axis=1, root_dir=OUTPUT_DIR) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
